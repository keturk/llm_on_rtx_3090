=== LLM Comprehensive Benchmark Suite ===
Date: Sun Nov 16 09:21:50 PM PST 2025
System: Dell T5820 + RTX 3090 (24GB)

✅ GPU metrics logger detected: gpu_metrics_20251116_212129.csv
   GPU utilization will be captured accurately

## Checking Installed Models

✅ llama3.2:3b - installed
✅ llama3.1:8b - installed
✅ mistral:7b - installed
✅ qwen2.5:7b - installed
✅ phi3:14b - installed
✅ qwen2.5:14b - installed
✅ gemma2:27b - installed
✅ qwen2.5:32b - installed
✅ codellama:34b - installed
✅ deepseek-coder:33b - installed

## Performance Results

| Model | Size | VRAM (MB) | Temp °C | Tokens/sec | Time (s) | Quality |
|-------|------|-----------|---------|------------|----------|---------|
| llama3.2:3b | 2.0 | 3654 | 59 | 48.3 | 2.564243722 | Good |
| llama3.1:8b | 4.9 | 6282 | 60 | 47.1 | 3.926597245 | Very Good |
| mistral:7b | 4.4 | 5976 | 62 | 65.3 | 3.276401424 | Very Good |
| qwen2.5:7b | 4.7 | 5744 | 61 | 30.5 | 3.015361145 | Very Good |
| phi3:14b | 7.9 | 9696 | 62 | 31.7 | 3.497405848 | Excellent |
| qwen2.5:14b | 9.0 | 10392 | 62 | 25.1 | 4.177409043 | Excellent |
| gemma2:27b | 15 | 17950 | 63 | 20.8 | 6.532806063 | Excellent+ |
| qwen2.5:32b | 19 | 21014 | 64 | 20.2 | 7.863970789 | Best |
| codellama:34b | 19 | 20588 | 64 | 22.4 | 6.957622849 | Best |
| deepseek-coder:33b | 18 | 20502 | 63 | 19.9 | 6.509123702 | Best |

## Detailed Prompt Analysis

### llama3.2:3b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.174193215 | 18.3 | ~40 tokens |
| reasoning | 2.693741286 | 52.3 | ~141 tokens |
| coding | 2.791136441 | 53.3 | ~149 tokens |
| creative | 2.095970027 | 17.6 | ~37 tokens |
| math | 2.758602079 | 44.5 | ~123 tokens |

### llama3.1:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.865161636 | 17.1 | ~49 tokens |
| reasoning | 4.381382726 | 51.5 | ~226 tokens |
| coding | 4.898470668 | 50.4 | ~247 tokens |
| creative | 2.705934354 | 16.2 | ~44 tokens |
| math | 4.191085378 | 35.7 | ~150 tokens |

### mistral:7b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.123403566 | 22.6 | ~48 tokens |
| reasoning | 3.303611616 | 65.9 | ~218 tokens |
| coding | 4.140222874 | 61.3 | ~254 tokens |
| creative | 1.967097969 | 19.8 | ~39 tokens |
| math | 2.976637986 | 42.3 | ~126 tokens |

### qwen2.5:7b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.089951965 | 27.5 | ~85 tokens |
| reasoning | 3.096976790 | 34.2 | ~106 tokens |
| coding | 5.327795731 | 58.5 | ~312 tokens |
| creative | 2.612452142 | 17.2 | ~45 tokens |
| math | 4.419854599 | 37.5 | ~166 tokens |

### phi3:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.082802417 | 17.8 | ~55 tokens |
| reasoning | 3.635774942 | 39.3 | ~143 tokens |
| coding | 5.569173169 | 42.9 | ~239 tokens |
| creative | 2.832350966 | 17.6 | ~50 tokens |
| math | 4.080489325 | 30.8 | ~126 tokens |

### qwen2.5:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.898242220 | 16.1 | ~63 tokens |
| reasoning | 4.545385576 | 28.1 | ~128 tokens |
| coding | 8.790926420 | 41.1 | ~362 tokens |
| creative | 3.739165229 | 14.7 | ~55 tokens |
| math | 8.036037014 | 24.8 | ~200 tokens |

### gemma2:27b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 5.636566642 | 13.1 | ~74 tokens |
| reasoning | 6.589839604 | 21.3 | ~141 tokens |
| coding | 16.684290684 | 23.1 | ~386 tokens |
| creative | 5.149026899 | 14.3 | ~74 tokens |
| math | 7.817492102 | 15.6 | ~122 tokens |

### qwen2.5:32b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 6.264238485 | 14.0 | ~88 tokens |
| reasoning | 6.941652458 | 18.1 | ~126 tokens |
| coding | 13.020275816 | 22.9 | ~299 tokens |
| creative | 5.738455619 | 13.5 | ~78 tokens |
| math | 9.554225789 | 16.1 | ~154 tokens |

### codellama:34b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 6.340671417 | 16.4 | ~104 tokens |
| reasoning | 7.125446832 | 22.7 | ~162 tokens |
| coding | 7.399641491 | 19.3 | ~143 tokens |
| creative | 5.141053159 | 15.5 | ~80 tokens |
| math | 9.214405998 | 17.0 | ~157 tokens |

### deepseek-coder:33b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 8.292456039 | 20.1 | ~167 tokens |
| reasoning | 6.466479993 | 20.5 | ~133 tokens |
| coding | 9.889548703 | 19.4 | ~192 tokens |
| creative | 5.216650584 | 15.9 | ~83 tokens |
| math | 10.298615231 | 18.9 | ~195 tokens |

## Recommendations

Based on RTX 3090 (24GB VRAM) testing:

- **Fast responses**: llama3.2:3b or mistral:7b (50-60 tok/s)
- **Daily use**: llama3.1:8b or qwen2.5:7b (40-50 tok/s)
- **High quality**: qwen2.5:14b or phi3:14b (30-40 tok/s)
- **Maximum quality**: qwen2.5:32b (15-25 tok/s)
- **Coding tasks**: codellama:34b or deepseek-coder:33b

=== Benchmark Complete ===

Results saved to: /home/llmuser/llm_on_rtx_3090/llm-docker/scripts/../benchmark_results/benchmark_20251116_212150.md
Timing markers saved to: /home/llmuser/llm_on_rtx_3090/llm-docker/scripts/../benchmark_results/benchmark_20251116_212150.md.timing

GPU metrics were logged. Run analyzer for accurate GPU utilization:
  ./scripts/analyze-gpu-metrics.sh
