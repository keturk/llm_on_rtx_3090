=== LLM Comprehensive Benchmark Suite ===
Date: Wed Dec 17 09:44:59 PM PST 2025
System: Dell T5820 + RTX 3090 (24GB)
Models: Original + 2025 New (DeepSeek-R1, Qwen3, Gemma3)

âœ… GPU metrics logger detected: gpu_metrics_20251217_213121.csv
   GPU utilization will be captured accurately

## Checking Installed Models

âœ… llama3.2:3b - installed
âœ… llama3.1:8b - installed
âœ… mistral:7b - installed
âœ… qwen2.5:7b - installed
âœ… qwen3:8b - installed
âœ… deepseek-r1:8b - installed
âœ… granite3-dense:8b - installed
âœ… dolphin3 - installed
âœ… gemma3:4b - installed
âœ… nemotron-mini:4b - installed
âœ… ministral-3:3b - installed
âœ… phi3.5 - installed
âœ… phi4-mini - installed
âœ… granite3.1-moe:3b - installed
âœ… ministral-3:8b - installed
âœ… phi3:14b - installed
âœ… phi4 - installed
âœ… qwen2.5:14b - installed
âœ… qwen3:14b - installed
âœ… deepseek-r1:14b - installed
âœ… gemma3:12b - installed
âœ… qwen2.5-coder:14b - installed
âœ… ministral-3:14b - installed
âœ… codestral:22b - installed
âœ… mistral-small:24b - installed
âœ… gemma2:27b - installed
âœ… gemma3:27b - installed
âœ… qwen3:30b-a3b - installed
âœ… qwen3-coder:30b - installed
âœ… nemotron-3-nano:30b - installed
âœ… qwen2.5:32b - installed
âœ… qwq:32b - installed
âœ… deepseek-r1:32b - installed
âœ… codellama:34b - installed
âœ… deepseek-coder:33b - installed

Testing 35 models...

## Performance Results

| Model | Size | VRAM (MB) | Temp Â°C | Tokens/sec | Time (s) | Quality |
|-------|------|-----------|---------|------------|----------|---------|
| llama3.2:3b | 2.0 | 3590 | 42 | 47.4 | 2.508899061 | Good |
| llama3.1:8b | 4.9 | 6164 | 45 | 45.4 | 4.249635555 | Very Good |
| mistral:7b | 4.4 | 5712 | 47 | 66.6 | 3.480148327 | Very Good |
| qwen2.5:7b | 4.7 | 5662 | 48 | 30.5 | 3.006972654 | Very Good |
| qwen3:8b ðŸ†• | 5.2 | 6316 | 51 | 63.7 | 5.396637506 | Very Good |
| deepseek-r1:8b ðŸ†• | 5.2 | 6316 | 53 | 63.3 | 6.030879253 | Very Good |
| granite3-dense:8b | 4.9 | 6452 | 53 | 44.5 | 3.255853649 | Very Good |
| dolphin3 | 4.9 | 6164 | 53 | 37.9 | 3.453107550 | Good |
| gemma3:4b ðŸ†• | 3.3 | 4634 | 52 | 28.7 | 4.179860144 | Good |
| nemotron-mini:4b | 2.7 | 4136 | 53 | 54.2 | 3.851354581 | Good |
| ministral-3:3b | 3.0 | 5344 | 53 | 33.5 | 3.902831900 | Good |
| phi3.5 | 2.2 | 4624 | 54 | 96.2 | 2.347241268 | Good |
| phi4-mini | 2.5 | 4252 | 54 | 42.4 | 3.321590821 | Good |
| granite3.1-moe:3b | 2.0 | 3248 | 53 | 60.3 | 1.904613500 | Good |
| ministral-3:8b | 6.0 | 8112 | 55 | 30.1 | 4.941333036 | Very Good |
| phi3:14b | 7.9 | 9394 | 55 | 34.7 | 3.076545172 | Excellent |
| phi4 | 2.5
9.1 | 10398 | 55 | 31.4 | 3.813564966 | Good |
| qwen2.5:14b | 9.0 | 10278 | 56 | 28.7 | 4.282067655 | Excellent |
| qwen3:14b ðŸ†• | 9.3 | 10222 | 57 | 39.5 | 7.708505127 | Excellent |
| deepseek-r1:14b ðŸ†• | 9.0 | 10268 | 59 | 50.3 | 10.525338954 | Excellent |
| gemma3:12b ðŸ†• | 8.1 | 9650 | 57 | 21.4 | 5.919635981 | Excellent |
| qwen2.5-coder:14b | 9.0 | 10278 | 57 | 29.2 | 4.515999180 | Excellent |
| ministral-3:14b | 9.1 | 11072 | 57 | 25.4 | 6.824187731 | Excellent |
| codestral:22b | 12 | 13948 | 58 | 36.3 | 5.886613390 | Good |
| mistral-small:24b | 14 | 15198 | 58 | 25.9 | 5.351180254 | Good |
| gemma2:27b | 15 | 17884 | 58 | 22.1 | 5.949752131 | Excellent+ |
| gemma3:27b ðŸ†• | 17 | 18706 | 58 | 17.7 | 10.011222542 | Excellent+ |
| qwen3:30b-a3b ðŸ†• | 18 | 18998 | 56 | 35.0 | 8.975705631 | Excellent+ |
| qwen3-coder:30b ðŸ†• | 18 | 18996 | 55 | 24.0 | 8.110485555 | Excellent+ |
| nemotron-3-nano:30b | 24 | 23354 | 55 | 22.8 | 8.913192470 | Excellent+ |
| qwen2.5:32b | 19 | 20854 | 56 | 19.6 | 6.007348507 | Best |
| qwq:32b | 19 | 20854 | 63 | 31.5 | 22.882283668 | Best |
| deepseek-r1:32b ðŸ†• | 19 | 20854 | 61 | 29.7 | 14.580854352 | Best |
| codellama:34b | 19 | 20046 | 58 | 22.9 | 5.522003390 | Best |
| deepseek-coder:33b | 18 | 20028 | 57 | 21.5 | 5.481938302 | Best |

## Detailed Prompt Analysis

### llama3.2:3b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.193347209 | 17.7 | ~39 tokens |
| reasoning | 2.767371759 | 57.0 | ~158 tokens |
| coding | 2.586518927 | 47.5 | ~123 tokens |
| creative | 2.129350873 | 16.9 | ~36 tokens |
| math | 2.779853549 | 46.0 | ~128 tokens |

### llama3.1:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.860176603 | 16.7 | ~48 tokens |
| reasoning | 4.097467710 | 51.2 | ~210 tokens |
| coding | 5.104676387 | 56.4 | ~288 tokens |
| creative | 2.783821354 | 18.6 | ~52 tokens |
| math | 3.800091200 | 38.4 | ~146 tokens |

### mistral:7b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.013114752 | 20.8 | ~42 tokens |
| reasoning | 2.652274808 | 62.9 | ~167 tokens |
| coding | 2.924345420 | 49.2 | ~144 tokens |
| creative | 1.884596983 | 19.1 | ~36 tokens |
| math | 3.481516553 | 53.9 | ~188 tokens |

### qwen2.5:7b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.670870486 | 22.8 | ~61 tokens |
| reasoning | 2.855568636 | 36.4 | ~104 tokens |
| coding | 4.967361972 | 65.0 | ~323 tokens |
| creative | 2.343046394 | 17.4 | ~41 tokens |
| math | 3.966691414 | 36.8 | ~146 tokens |

### qwen3:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 4.828566623 | 55.0 | ~266 tokens |
| reasoning | 5.170279179 | 62.4 | ~323 tokens |
| coding | 12.109924484 | 86.7 | ~1051 tokens |
| creative | 8.432392627 | 74.8 | ~631 tokens |
| math | 30.360883469 | 62.8 | ~1908 tokens |

### deepseek-r1:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 5.381494431 | 57.6 | ~310 tokens |
| reasoning | 5.601269119 | 66.9 | ~375 tokens |
| coding | 15.615687453 | 92.5 | ~1446 tokens |
| creative | 7.218120370 | 67.0 | ~484 tokens |
| math | 20.251568983 | 56.6 | ~1147 tokens |

### granite3-dense:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.136118790 | 16.8 | ~36 tokens |
| reasoning | 2.875738992 | 50.7 | ~146 tokens |
| coding | 2.810276645 | 40.9 | ~115 tokens |
| creative | 2.093741269 | 18.6 | ~39 tokens |
| math | 2.845392990 | 29.1 | ~83 tokens |

### dolphin3

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.795988739 | 15.7 | ~44 tokens |
| reasoning | 3.166241888 | 34.4 | ~109 tokens |
| coding | 2.937947434 | 22.1 | ~65 tokens |
| creative | 2.790177048 | 17.5 | ~49 tokens |
| math | 3.416708052 | 28.6 | ~98 tokens |

### gemma3:4b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.768254013 | 16.4 | ~62 tokens |
| reasoning | 3.972909396 | 29.4 | ~117 tokens |
| coding | 8.762507269 | 65.2 | ~572 tokens |
| creative | 3.561697338 | 16.0 | ~57 tokens |
| math | 5.158806193 | 31.2 | ~161 tokens |

### nemotron-mini:4b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.580028350 | 27.1 | ~70 tokens |
| reasoning | 2.851677008 | 45.5 | ~130 tokens |
| coding | 4.726901074 | 57.9 | ~274 tokens |
| creative | 2.218897200 | 14.4 | ~32 tokens |
| math | 3.441409357 | 45.3 | ~156 tokens |

### ministral-3:3b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.642698263 | 18.1 | ~66 tokens |
| reasoning | 3.849321609 | 30.9 | ~119 tokens |
| coding | 4.780594238 | 52.7 | ~252 tokens |
| creative | 3.588032097 | 16.1 | ~58 tokens |
| math | 3.958793518 | 28.7 | ~114 tokens |

### phi3.5

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 1.513169784 | 26.4 | ~40 tokens |
| reasoning | 1.727808360 | 64.2 | ~111 tokens |
| coding | 2.421528942 | 86.7 | ~210 tokens |
| creative | 1.638556393 | 40.8 | ~67 tokens |
| math | 51.522300871 | 134.6 | ~6936 tokens |

### phi4-mini

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.722778869 | 17.6 | ~48 tokens |
| reasoning | 3.397250479 | 48.8 | ~166 tokens |
| coding | 5.225426444 | 72.1 | ~377 tokens |
| creative | 2.514669165 | 16.7 | ~42 tokens |
| math | 4.045633679 | 38.8 | ~157 tokens |

### granite3.1-moe:3b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 1.631612093 | 37.3 | ~61 tokens |
| reasoning | 1.787706898 | 76.0 | ~136 tokens |
| coding | 2.271602802 | 87.1 | ~198 tokens |
| creative | 1.472181186 | 19.6 | ~29 tokens |
| math | 2.309857336 | 77.9 | ~180 tokens |

### ministral-3:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 4.464629075 | 15.0 | ~67 tokens |
| reasoning | 5.170477950 | 29.7 | ~154 tokens |
| coding | 7.242708200 | 45.2 | ~328 tokens |
| creative | 4.433226526 | 14.8 | ~66 tokens |
| math | 5.822675329 | 27.6 | ~161 tokens |

### phi3:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 2.684392640 | 23.4 | ~63 tokens |
| reasoning | 3.168965924 | 36.2 | ~115 tokens |
| coding | 7.022291486 | 51.9 | ~365 tokens |
| creative | 2.293684724 | 18.3 | ~42 tokens |
| math | 4.028834202 | 33.5 | ~135 tokens |

### phi4

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.058225864 | 17.9 | ~55 tokens |
| reasoning | 4.198050416 | 35.4 | ~149 tokens |
| coding | 6.309905133 | 45.6 | ~288 tokens |
| creative | 3.282842507 | 22.5 | ~74 tokens |
| math | 3.994941924 | 26.5 | ~106 tokens |

### qwen2.5:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.365775826 | 16.3 | ~55 tokens |
| reasoning | 3.981143582 | 31.1 | ~124 tokens |
| coding | 7.800041864 | 44.7 | ~349 tokens |
| creative | 2.986268951 | 16.4 | ~49 tokens |
| math | 6.919723267 | 27.6 | ~191 tokens |

### qwen3:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 17.124871314 | 56.2 | ~963 tokens |
| reasoning | 8.030840421 | 41.7 | ~335 tokens |
| coding | 35.150718990 | 60.6 | ~2132 tokens |
| creative | 90.921306892 | 44.8 | ~4079 tokens |
| math | 35.592829306 | 40.7 | ~1450 tokens |

### deepseek-r1:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 6.126691094 | 35.0 | ~215 tokens |
| reasoning | 9.269247976 | 52.9 | ~491 tokens |
| coding | 18.350849573 | 57.1 | ~1049 tokens |
| creative | 6.756997881 | 34.0 | ~230 tokens |
| math | 9.615451725 | 30.2 | ~291 tokens |

### gemma3:12b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 5.441812446 | 13.7 | ~75 tokens |
| reasoning | 5.739926718 | 21.2 | ~122 tokens |
| coding | 16.864936687 | 41.9 | ~708 tokens |
| creative | 5.244282388 | 14.3 | ~75 tokens |
| math | 8.244893975 | 23.2 | ~192 tokens |

### qwen2.5-coder:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 3.704281408 | 22.6 | ~84 tokens |
| reasoning | 4.827509831 | 39.5 | ~191 tokens |
| coding | 6.902501044 | 40.4 | ~279 tokens |
| creative | 2.996500080 | 16.0 | ~48 tokens |
| math | 9.332508051 | 32.6 | ~305 tokens |

### ministral-3:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 12.901823946 | 13.3 | ~172 tokens |
| reasoning | 13.846539063 | 17.9 | ~248 tokens |
| coding | 16.962707345 | 25.4 | ~431 tokens |
| creative | 12.858501332 | 13.5 | ~174 tokens |
| math | 13.894263464 | 15.7 | ~219 tokens |

### codestral:22b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 15.750768979 | 14.2 | ~224 tokens |
| reasoning | 18.183896410 | 20.5 | ~373 tokens |
| coding | 17.992945282 | 17.5 | ~315 tokens |
| creative | 15.581514639 | 13.9 | ~217 tokens |
| math | 18.168771047 | 17.5 | ~318 tokens |

### mistral-small:24b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 18.706369581 | 13.3 | ~249 tokens |
| reasoning | 19.664048558 | 16.4 | ~323 tokens |
| coding | 23.629226619 | 19.2 | ~456 tokens |
| creative | 18.352737048 | 13.5 | ~248 tokens |
| math | 20.279276383 | 14.5 | ~295 tokens |

### gemma2:27b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 20.382678163 | 13.0 | ~265 tokens |
| reasoning | 21.198183797 | 14.7 | ~312 tokens |
| coding | 30.827745823 | 18.2 | ~564 tokens |
| creative | 20.599475067 | 13.8 | ~286 tokens |
| math | 22.288155488 | 13.8 | ~309 tokens |

### gemma3:27b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 22.507673554 | 12.9 | ~292 tokens |
| reasoning | 23.505256085 | 15.1 | ~357 tokens |
| coding | 41.917584760 | 20.2 | ~848 tokens |
| creative | 22.064312427 | 13.0 | ~289 tokens |
| math | 24.753081628 | 13.6 | ~338 tokens |

### qwen3:30b-a3b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 22.768444832 | 15.4 | ~352 tokens |
| reasoning | 23.787223237 | 20.8 | ~495 tokens |
| coding | 41.036780964 | 54.6 | ~2242 tokens |
| creative | 30.834749482 | 31.9 | ~986 tokens |
| math | 36.712624793 | 34.4 | ~1264 tokens |

### qwen3-coder:30b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 21.564871396 | 13.2 | ~286 tokens |
| reasoning | 22.249431743 | 17.2 | ~384 tokens |
| coding | 28.375922798 | 28.7 | ~817 tokens |
| creative | 21.427743794 | 13.3 | ~286 tokens |
| math | 23.116357905 | 16.7 | ~388 tokens |

### nemotron-3-nano:30b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 31.162361295 | 13.5 | ~423 tokens |
| reasoning | 33.508624012 | 15.9 | ~535 tokens |
| coding | 48.169623207 | 18.9 | ~912 tokens |
| creative | 48.680266665 | 16.6 | ~811 tokens |
| math | 43.570767818 | 15.2 | ~664 tokens |

### qwen2.5:32b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 25.281948223 | 13.2 | ~335 tokens |
| reasoning | 26.520681048 | 15.1 | ~401 tokens |
| coding | 31.418177142 | 16.9 | ~531 tokens |
| creative | 24.592173271 | 13.1 | ~323 tokens |
| math | 27.791826586 | 13.9 | ~387 tokens |

### qwq:32b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 32.364492638 | 17.8 | ~579 tokens |
| reasoning | 39.260086301 | 22.6 | ~890 tokens |
| coding | 79.573229955 | 26.2 | ~2086 tokens |
| creative | 55.788226565 | 22.1 | ~1235 tokens |
| math | 79.511711846 | 18.8 | ~1495 tokens |

### deepseek-r1:32b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 25.451549173 | 13.1 | ~334 tokens |
| reasoning | 35.932791830 | 20.7 | ~747 tokens |
| coding | 45.782742821 | 22.4 | ~1029 tokens |
| creative | 36.210287718 | 20.2 | ~735 tokens |
| math | 31.941052533 | 15.1 | ~484 tokens |

### codellama:34b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 23.721012944 | 13.5 | ~321 tokens |
| reasoning | 25.015449419 | 16.1 | ~403 tokens |
| coding | 25.573121794 | 15.2 | ~390 tokens |
| creative | 22.948603251 | 13.2 | ~304 tokens |
| math | 25.383446504 | 14.1 | ~360 tokens |

### deepseek-coder:33b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| simple | 22.994289304 | 13.0 | ~301 tokens |
| reasoning | 23.718914674 | 14.7 | ~351 tokens |
| coding | 26.690946630 | 16.4 | ~438 tokens |
| creative | 23.345542086 | 13.8 | ~323 tokens |
| math | 28.422977969 | 16.4 | ~468 tokens |

## Recommendations

Based on RTX 3090 (24GB VRAM) testing:

### Speed Priority (50-60+ tok/s)
- llama3.2:3b, mistral:7b, qwen3:8b

### Daily Use (40-50 tok/s)
- llama3.1:8b, qwen2.5:7b, deepseek-r1:8b

### High Quality (25-40 tok/s)
- qwen3:14b, deepseek-r1:14b, gemma3:12b

### Maximum Quality (15-25 tok/s)
- qwen3:30b-a3b (MoE - fast for size!), deepseek-r1:32b, gemma3:27b

### Reasoning Tasks
- deepseek-r1:14b (best value), deepseek-r1:32b (best quality)

### Coding Tasks
- qwen2.5-coder:14b, deepseek-coder:33b, codellama:34b

=== Benchmark Complete ===

Results saved to: /home/llmuser/llm_on_rtx_3090/llm-docker/scripts/../benchmark_results/benchmark_20251217_214459.md
Timing markers saved to: /home/llmuser/llm_on_rtx_3090/llm-docker/scripts/../benchmark_results/benchmark_20251217_214459.md.timing

GPU metrics were logged. Run analyzer for accurate GPU utilization:
  ./scripts/analyze-gpu-metrics.sh
