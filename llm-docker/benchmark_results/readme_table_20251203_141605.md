## Updated Performance Table for README.md

| Model | VRAM Usage | Tokens/sec | Quality |
|-------|------------|------------|---------|
| llama3.2:3b | ~3GB | 44.3 | Good |
| llama3.1:8b | ~6GB | 43.0 | Very Good |
| mistral:7b | ~5GB | 68.0 | Very Good |
| qwen2.5:7b | ~5GB | 30.7 | Very Good |
| qwen3:8b ðŸ†• | ~6GB | 60.5 | Very Good |
| deepseek-r1:8b ðŸ†• | ~6GB | 57.8 | Very Good |
| gemma3:4b ðŸ†• | ~5GB | 28.3 | Good |
| phi3:14b | ~9GB | 30.8 | Excellent |
| qwen2.5:14b | ~10GB | 27.1 | Excellent |
| qwen3:14b ðŸ†• | ~9GB | 39.4 | Excellent |
| deepseek-r1:14b ðŸ†• | ~10GB | 48.3 | Excellent |
| gemma3:12b ðŸ†• | ~10GB | 21.8 | Excellent |
| qwen2.5-coder:14b | ~10GB | 29.7 | Excellent |
| gemma2:27b | ~17GB | 19.5 | Excellent+ |
| gemma3:27b ðŸ†• | ~19GB | 17.2 | Excellent+ |
| qwen3:30b-a3b ðŸ†• | ~18GB | 33.8 | Excellent+ |
| qwen2.5:32b | ~20GB | 19.9 | Best |
| deepseek-r1:32b ðŸ†• | ~20GB | 28.8 | Best |
| codellama:34b | ~20GB | 22.7 | Best |
| deepseek-coder:33b | ~19GB | 21.9 | Best |

