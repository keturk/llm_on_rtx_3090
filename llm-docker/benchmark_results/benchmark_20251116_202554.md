=== LLM Comprehensive Benchmark Suite ===
Date: Sun Nov 16 08:25:54 PM PST 2025
System: Dell T5820 + RTX 3090 (24GB)

## Checking Installed Models

✅ llama3.2:3b - installed
✅ llama3.1:8b - installed
✅ mistral:7b - installed
✅ qwen2.5:7b - installed
✅ phi3:14b - installed
✅ qwen2.5:14b - installed
✅ gemma2:27b - installed
✅ qwen2.5:32b - installed
✅ codellama:34b - installed
✅ deepseek-coder:33b - installed

## Performance Results

| Model | Size | VRAM (MB) | GPU Util % | Temp °C | Tokens/sec | Time (s) | Quality |
|-------|------|-----------|------------|---------|------------|----------|---------|
| llama3.2:3b | 2.0 | 3622 | 0 | 58 | 51.4 | 2.739561946 | Good |
| llama3.1:8b | 4.9 | 6250 | 0 | 60 | 51.6 | 4.085177083 | Very Good |
| mistral:7b | 4.4 | 5944 | 0 | 61 | 63.7 | 3.198538070 | Very Good |
| qwen2.5:7b | 4.7 | 5712 | 0 | 61 | 29.5 | 3.081490144 | Very Good |
| phi3:14b | 7.9 | 9664 | 0 | 61 | 32.1 | 3.169330410 | Excellent |
| qwen2.5:14b | 9.0 | 10360 | 0 | 62 | 23.4 | 4.096238528 | Excellent |
| gemma2:27b | 15 | 17918 | 0 | 63 | 19.6 | 6.524317602 | Excellent+ |
| qwen2.5:32b | 19 | 20982 | 4 | 63 | 19.6 | 7.626079733 | Best |
| codellama:34b | 19 | 20556 | 4 | 63 | 21.1 | 6.586000726 | Best |
| deepseek-coder:33b | 18 | 20470 | 0 | 63 | 20.7 | 6.597001357 | Best |

## Detailed Prompt Analysis

### llama3.1:8b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| math | 3.510190256 | 33.9 | ~119 tokens |
| coding | 5.015554894 | 52.4 | ~263 tokens |
| simple | 2.892117039 | 16.5 | ~48 tokens |
| creative | 2.792428240 | 18.6 | ~52 tokens |
| reasoning | 3.834433243 | 44.8 | ~172 tokens |

### qwen2.5:14b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| math | 7.920361717 | 26.2 | ~208 tokens |
| coding | 8.457670796 | 40.3 | ~341 tokens |
| simple | 3.877258940 | 16.2 | ~63 tokens |
| creative | 3.498203859 | 16.2 | ~57 tokens |
| reasoning | 4.307708887 | 26.2 | ~113 tokens |

### qwen2.5:32b

| Prompt Type | Time (s) | Tokens/sec | Output Length |
|-------------|----------|------------|---------------|
| math | 8.686580905 | 15.5 | ~135 tokens |
| coding | 14.114635862 | 22.7 | ~321 tokens |
| simple | 6.260868726 | 14.5 | ~91 tokens |
| creative | 5.862675818 | 14.1 | ~83 tokens |
| reasoning | 8.250403360 | 21.5 | ~178 tokens |

## Recommendations

Based on RTX 3090 (24GB VRAM) testing:

- **Fast responses**: llama3.2:3b or mistral:7b (50-60 tok/s)
- **Daily use**: llama3.1:8b or qwen2.5:7b (40-50 tok/s)
- **High quality**: qwen2.5:14b or phi3:14b (30-40 tok/s)
- **Maximum quality**: qwen2.5:32b (15-25 tok/s)
- **Coding tasks**: codellama:34b or deepseek-coder:33b

=== Benchmark Complete ===

Results saved to: /home/llmuser/llm_on_rtx_3090/llm-docker/scripts/../benchmark_results/benchmark_20251116_202554.md
